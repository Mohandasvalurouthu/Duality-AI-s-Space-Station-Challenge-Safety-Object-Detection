# -*- coding: utf-8 -*-
"""Main_Frame.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uPGjaVBw4m1JJXIoOgbK5YNBzrABBPSY
"""

!pip install ultralytics

from ultralytics import YOLO
print("YOLO imported successfully")

from google.colab import drive
drive.mount('/content/drive')

from ultralytics import YOLO
from IPython.display import display
from PIL import Image
import os

model = YOLO("yolov8n.pt")

image_folder = "/content/drive/MyDrive/colab_space-images"

print("Files:", os.listdir(image_folder))

for img_file in os.listdir(image_folder):
    img_path = os.path.join(image_folder, img_file)
    results = model.predict(source=img_path, save=True)
    output_image = results[0].plot(save=False)
    display(Image.fromarray(output_image))

!pip install tensorflow

!unzip dataset.zip

!ls dataset/train

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = 224
BATCH_SIZE = 16

train_gen = ImageDataGenerator(rescale=1./255)
train_data = train_gen.flow_from_directory(
    'dataset/train',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_gen = ImageDataGenerator(rescale=1./255)
test_data = test_gen.flow_from_directory(
    'dataset/test',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(train_data.num_classes, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

model.fit(
    train_data,
    epochs=10,
    validation_data=test_data
)

model.save("space_cnn_model.h5")

!ls

!unzip dataset.zip

!ls

!ls dataset/train

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = 224
BATCH_SIZE = 16

train_gen = ImageDataGenerator(rescale=1./255)
train_data = train_gen.flow_from_directory(
    'dataset/train',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_gen = ImageDataGenerator(rescale=1./255)
test_data = test_gen.flow_from_directory(
    'dataset/test',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(train_data.num_classes, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

model.fit(
    train_data,
    epochs=10,
    validation_data=test_data
)

model.save("space_cnn_model.h5")

print(train_data.class_indices)

import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model
import tensorflow as tf

# ðŸ”¹ Load trained model
model = load_model("space_cnn_model.h5")

# ðŸ”¹ Load new image (change file name to your uploaded image)
# Correct target_size to match model input_shape (IMG_SIZE, IMG_SIZE)
img_path = "/content/dataset/train/oxygen_cylinder/Oxygen_Cylinder_test_1.jpeg" # Using a valid image from the dataset
img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))

# Convert to array and normalize
img = image.img_to_array(img)
img = img / 255.0

# Add batch dimension
img = np.expand_dims(img, axis=0)

# Explicitly reshape to ensure the correct input shape (1, IMG_SIZE, IMG_SIZE, 3)
# This handles the unexpected extra dimension reported in the error.
img = img.reshape(1, IMG_SIZE, IMG_SIZE, 3)

# ðŸ”¹ Predict
prediction = model.predict(img)
class_index = np.argmax(prediction)

# ðŸ”¹ Print class index
print("Class index:", class_index)

# ðŸ”¹ Map index to class name
class_labels = {v:k for k,v in train_data.class_indices.items()}
print("Predicted class:", class_labels[class_index])

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image

base_dir = "/content/dataset/train/"   # parent directory
images = []
original_images = []
image_paths = []

# Traverse all sub-directories
for root, dirs, files in os.walk(base_dir):
    for file in files:
        if file.lower().endswith(('.jpg', '.jpeg', '.png')):
            img_path = os.path.join(root, file)
            image_paths.append(img_path)

            img = image.load_img(img_path, target_size=(224, 224))
            original_images.append(img)

            img_array = image.img_to_array(img) / 255.0
            images.append(img_array)

# Convert to numpy array
images = np.array(images)
print("Total images loaded:", images.shape[0])

# Predict
predictions = model.predict(images, verbose=1)

class_labels = {v: k for k, v in train_data.class_indices.items()}

# Show predictions
for i, pred in enumerate(predictions):
    plt.imshow(original_images[i])
    plt.title(f"{os.path.basename(image_paths[i])} â†’ {class_labels[np.argmax(pred)]}")
    plt.axis('off')
    plt.show()